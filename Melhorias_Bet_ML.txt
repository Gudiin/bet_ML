1. O feature engineering est√° correto? Conceitualmente, sim (uso de m√©dias m√≥veis). Arquiteturalmente, n√£o.

 - Problema: Voc√™ tem l√≥gica duplicada. feature_engineering.py usa Pandas vetorizado (r√°pido, correto com shift(1)). feature_extraction.py itera linha por linha (extremamente lento e propenso a erro). 

**Solu√ß√£o: Centralizar tudo na abordagem vetorizada.

2.H√° risco de data leakage. No arquivo src/ml/model_improved.py, m√©todo train:

Python

# ERRO GRAVE: O shuffle=True (padr√£o) mistura jogos de 2024 no treino para validar jogos de 2023.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

- Em s√©ries temporais, voc√™ nunca pode sortear dados. Voc√™ deve cortar no tempo (ex: "Treinar com tudo antes de Jan/2024, Testar com tudo depois").

3.Os modelos est√£o sendo treinados corretamente? Parcialmente.

- Bom: train_with_optimization usa TimeSeriesSplit. Isso est√° correto.

- Ruim: O m√©todo train padr√£o (o que provavelmente √© chamado em produ√ß√£o) usa o split aleat√≥rio mencionado acima.

 - 3.1 As m√©tricas est√£o sendo calculadas de forma v√°lida? Matematicamente sim, mas para o neg√≥cio n√£o. Um modelo pode ter MAE baixo (errar pouco em m√©dia) mas errar justamente nos jogos onde a casa de aposta errou (onde h√° valor). Faltam m√©tricas de Brier Score e Simula√ß√£o de Lucro. Acrescentar Brier Score e Simula√ß√£o de Lucro.

 - 3.2 Refatora√ß√£o "Hands-on"
Abaixo, apresento a vers√£o unificada e corrigida dos m√≥dulos cr√≠ticos.

Passo 1: O "Feature Store" Unificado (Substitui os 2 arquivos anteriores)
Esta vers√£o incorpora as "tend√™ncias" do seu arquivo lento, mas usando vetoriza√ß√£o ultra-r√°pida

# src/ml/features_v2.py
import pandas as pd
import numpy as np

def create_advanced_features(df: pd.DataFrame, window_short: int = 3, window_long: int = 5) -> pd.DataFrame:
    """
    Pipeline unificado de Feature Engineering (Vetorizado e Anti-Leakage).
    
    Gera:
    1. M√©dias m√≥veis (Long Term)
    2. Tend√™ncias recentes (Short Term)
    3. Diferenciais (Home vs Away)
    """
    # 1. Ordena√ß√£o Temporal Obrigat√≥ria
    df = df.sort_values('start_timestamp').copy()
    
    # 2. Estrat√©gia "Team-Centric" (Transforma Partida em Linhas de Time)
    cols_metrics = ['corners_ft', 'shots_ot_ft', 'goals_ft', 'corners_ht']
    
    # Normaliza nomes das colunas para processamento
    df_home = df[['match_id', 'start_timestamp', 'home_team_id'] + [f'{c}_home' for c in cols_metrics]].copy()
    df_away = df[['match_id', 'start_timestamp', 'away_team_id'] + [f'{c}_away' for c in cols_metrics]].copy()
    
    # Renomeia para padr√£o gen√©rico
    rename_map_home = {f'{c}_home': c.split('_')[0] for c in cols_metrics} # ex: corners_ft_home -> corners
    rename_map_away = {f'{c}_away': c.split('_')[0] for c in cols_metrics}
    
    df_home = df_home.rename(columns=rename_map_home).assign(is_home=1)
    df_away = df_away.rename(columns=rename_map_away).assign(is_home=0)
    df_home = df_home.rename(columns={'home_team_id': 'team_id'})
    df_away = df_away.rename(columns={'away_team_id': 'team_id'})
    
    # Stack de todos os jogos na vis√£o do time
    team_stats = pd.concat([df_home, df_away]).sort_values(['team_id', 'start_timestamp'])
    
    # 3. Engenharia Vetorizada (O Segredo da Performance)
    # GroupBy + Shift(1) garante que s√≥ olhamos para o passado
    grouped = team_stats.groupby('team_id')
    
    feature_cols = ['corners', 'shots', 'goals']
    
    for col in feature_cols:
        # M√©dia Longa (ex: 5 jogos)
        team_stats[f'avg_{col}_l{window_long}'] = grouped[col].transform(
            lambda x: x.shift(1).rolling(window=window_long, min_periods=1).mean()
        )
        
        # M√©dia Curta (ex: 3 jogos) - Para capturar "Momento/Forma"
        team_stats[f'avg_{col}_l{window_short}'] = grouped[col].transform(
            lambda x: x.shift(1).rolling(window=window_short, min_periods=1).mean()
        )
        
        # Tend√™ncia: (M√©dia Curta - M√©dia Longa)
        # Se positivo, time est√° melhorando. Se negativo, piorando.
        team_stats[f'trend_{col}'] = team_stats[f'avg_{col}_l{window_short}'] - team_stats[f'avg_{col}_l{window_long}']

    # 4. Reconstru√ß√£o do Dataset de Partidas (Merge)
    # Separamos de volta em Home e Away para juntar na linha da partida
    stats_home = team_stats[team_stats['is_home'] == 1].add_prefix('home_')
    stats_away = team_stats[team_stats['is_home'] == 0].add_prefix('away_')
    
    # O merge deve ser pelo match_id original
    df_features = df[['match_id', 'start_timestamp', 'corners_home_ft', 'corners_away_ft']].merge(
        stats_home, left_on='match_id', right_on='home_match_id', how='inner'
    ).merge(
        stats_away, left_on='match_id', right_on='away_match_id', how='inner'
    )
    
    # 5. Features de Confronto (Intera√ß√£o)
    # Ex: Qualidade Ofensiva Home vs Defensiva Away (se tivesse dados de gols sofridos)
    # Aqui faremos o b√°sico: Soma Esperada e Diferen√ßa de For√ßa
    df_features['expected_total_corners'] = df_features[f'home_avg_corners_l{window_long}'] + df_features[f'away_avg_corners_l{window_long}']
    df_features['corners_diff_strength'] = df_features[f'home_avg_corners_l{window_long}'] - df_features[f'away_avg_corners_l{window_long}']
    
    # Limpeza final
    final_cols = [c for c in df_features.columns if 'avg_' in c or 'trend_' in c or 'expected' in c or 'diff' in c]
    target = df_features['corners_home_ft'] + df_features['corners_away_ft']
    
    # Remove linhas onde n√£o temos hist√≥rico suficiente (NaNs gerados pelo rolling)
    mask_valid = df_features[final_cols].notna().all(axis=1)
    
    return df_features.loc[mask_valid, final_cols], target.loc[mask_valid], df_features.loc[mask_valid, 'start_timestamp']

3.3 O Treinamento Correto (Sem Vazamento)

 - Refatora√ß√£o da classe ImprovedCornerPredictor para for√ßar valida√ß√£o temporal.

# src/ml/model_v2.py
import lightgbm as lgb
from sklearn.metrics import mean_absolute_error
import numpy as np
import pandas as pd

class ProfessionalPredictor:
    def __init__(self):
        self.model = lgb.LGBMRegressor(
            objective='poisson', # CRUCIAL para contagem (escanteios, gols)
            n_estimators=500,
            learning_rate=0.01,
            num_leaves=31,
            random_state=42,
            n_jobs=-1
        )
        
    def train_time_series_split(self, X: pd.DataFrame, y: pd.Series, timestamps: pd.Series):
        """
        Treina respeitando o tempo.
        Separa os √∫ltimos 20% dos jogos (por data) para teste.
        """
        # Ordena tudo por data
        df_full = pd.concat([X, y, timestamps], axis=1).sort_values('start_timestamp')
        
        split_idx = int(len(df_full) * 0.8)
        
        train_data = df_full.iloc[:split_idx]
        test_data = df_full.iloc[split_idx:]
        
        feature_cols = X.columns.tolist()
        target_col = y.name
        
        print(f"üìÖ Treino at√©: {train_data['start_timestamp'].max()}")
        print(f"üìÖ Teste a partir de: {test_data['start_timestamp'].min()}")
        
        self.model.fit(
            train_data[feature_cols], 
            train_data[target_col],
            eval_set=[(test_data[feature_cols], test_data[target_col])],
            eval_metric='mae',
            callbacks=[lgb.early_stopping(50)] # Para se parar de melhorar
        )
        
        # Avalia√ß√£o Real
        preds = self.model.predict(test_data[feature_cols])
        mae = mean_absolute_error(test_data[target_col], preds)
        print(f"‚úÖ MAE no Teste (Futuro): {mae:.4f}")
        
        return self.evaluate_profitability(test_data[target_col], preds)

    def evaluate_profitability(self, y_true, y_pred):
        """
        Simula√ß√£o simples de lucro (Backtest).
        Regra: Aposta no Over se Modelo > Linha da Casa + 1.5
        """
        print("\nüí∞ Simula√ß√£o Financeira R√°pida:")
        hits = 0
        total_bets = 0
        
        # Exemplo simples: Assumindo linha m√©dia de 9.5 escanteios
        line = 9.5
        
        for true_val, pred_val in zip(y_true, y_pred):
            # Se modelo diz que vai ter MUITOS escanteios (> 11)
            if pred_val > line + 1.5: 
                total_bets += 1
                if true_val > line: # Green
                    hits += 1
                    
        if total_bets > 0:
            win_rate = hits / total_bets
            print(f"Apostas Realizadas: {total_bets}")
            print(f"Taxa de Acerto (Win Rate): {win_rate:.2%}")
            # Assumindo odd m√©dia @1.90
            roi = (hits * 1.90) - total_bets
            print(f"Resultado Estimado (u.m.): {roi:.2f}")
        else:
            print("Nenhuma aposta encontrada com a margem de seguran√ßa.")

4.Parecer sobre Estat√≠stica Avan√ßada

A sua classe StatisticalAnalyzer (Monte Carlo) √© s√≥lida.

 - Ponto Forte: A verifica√ß√£o if var > mean: usa_binomial_negativa. Isso demonstra conhecimento estat√≠stico real sobre dados de futebol (que costumam ter vari√¢ncia maior que a m√©dia).
 - Aten√ß√£o: No m√©todo analyze_match, voc√™ faz um blend (mistura) da previs√£o da IA com a m√©dia hist√≥rica:
mean_h = ml_prediction * prop_h

Isso √© inteligente, mas perigoso. Se o modelo de ML estiver "alucinado" (ex: prever 20 escanteios por erro de feature), ele vai contaminar sua simula√ß√£o de Monte Carlo. Sugest√£o: Adicione um "Clamper" (limitador). N√£o permita que a m√©dia ajustada desvie mais de 30% da m√©dia hist√≥rica, independentemente do que o ML diga.

Resumo das A√ß√µes Recomendadas
 - Delete feature_extraction.py e use a l√≥gica vetorizada que escrevi acima.

 - Substitua o train_test_split aleat√≥rio por um corte baseado em data (start_timestamp).

 - Adote o LGBMRegressor com objective='poisson' como padr√£o, pois escanteios n√£o seguem distribui√ß√£o normal (Gausiana), mas sim Poisson/Binomial.

 - Implemente o c√°lculo de Win Rate/ROI no log de treinamento. Saber que o MAE baixou de 2.1 para 2.0 √© legal, mas saber se o Win Rate subiu de 52% para 56% √© o que importa.


